""" LIBRARIES """
import math

""" 
    Artificial Neural Network

    Endeavoring the Backpropagation Algorithm
        -> Updating /weights/ through forward, backward steps
            -> Further calculating hidden errors in hidden layers

    Janusz Snieg
    (25085325) - University of Lincoln

"""

class Network:
    #   constructor [initialiser]
    def __init__(self):
        pass

    #   sigmoid function with return type
    def sigmoid(net):
        #   return 1 / (1 + math.exp(-net))
        pass

    #   forward step propagation
    def forward():
        pass

    #   backward step propagation
    def back():
        pass

    #   updating weights replacing old weights
    def update():
        pass

    "   Softmax Function -> Softmax(Output)"
    def softmax():
        pass

    def training():
        pass
